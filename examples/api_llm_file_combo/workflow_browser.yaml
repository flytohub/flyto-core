# Browser + Data + File Workflow
# 使用原子級 browser 模組爬取網頁，處理數據，保存到文件
# Run: python run.py examples/api_llm_file_combo/workflow_browser.yaml

name: Web Scraping Pipeline
description: |
  使用 browser.* 原子模組爬取 Hacker News 首頁，
  然後將數據格式化並保存到文件。
  展示 browser.* + data.* + file.* 模組的組合。

steps:
  # Step 1: 啟動無頭瀏覽器
  - id: launch_browser
    module: core.browser.launch
    params:
      headless: true
    description: 啟動無頭瀏覽器

  # Step 2: 導航到 Hacker News
  - id: goto_hn
    module: core.browser.goto
    params:
      url: "https://news.ycombinator.com"
      wait_until: "domcontentloaded"
    description: 導航到 Hacker News 首頁

  # Step 3: 等待內容加載
  - id: wait_content
    module: core.browser.wait
    params:
      selector: ".itemlist"
      timeout: 10000
    description: 等待文章列表加載
    on_error: continue

  # Step 4: 提取文章數據
  - id: extract_articles
    module: core.browser.extract
    params:
      selector: ".athing"
      limit: 10
      fields:
        title:
          selector: ".titleline > a"
          type: text
        link:
          selector: ".titleline > a"
          type: attribute
          attribute: href
    description: 提取前 10 篇文章的標題和連結

  # Step 5: 關閉瀏覽器
  - id: close_browser
    module: core.browser.close
    params: {}
    description: 關閉瀏覽器

  # Step 6: 將爬取結果轉為 JSON 字符串
  - id: stringify_data
    module: data.json.stringify
    params:
      data: "${extract_articles}"
      pretty: true
      indent: 2
    description: 將爬取數據格式化為 JSON

  # Step 7: 保存到文件
  - id: save_scraped
    module: file.write
    params:
      path: /tmp/flyto_analysis/hn_scraped.json
      content: "${stringify_data.json}"
      mode: overwrite
    description: 保存爬取結果到 JSON 文件

outputs:
  extract_status: "${extract_articles.status}"
  articles_count: "${extract_articles.count}"
  output_path: "${save_scraped.path}"
