#!/usr/bin/env python3
"""
æµ‹è¯• Spec Runner åŠ¨æ€éªŒè¯

æ¼”ç¤ºï¼š
1. ä½¿ç”¨ file.read è¯»å– Figma æå–çš„æ ·å¼
2. ä½¿ç”¨ file.read è¯»å–æœŸæœ›æ ·å¼
3. åŠ¨æ€æ¯”è¾ƒä¸¤è€…çš„ key è¦†ç›–ç‡
"""
import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from src.core.modules.atomic.verify.spec_runner import (
    run_spec_ruleset,
    execute_module_dynamic,
    extract_keys,
)


async def test_dynamic_spec():
    """æµ‹è¯•åŠ¨æ€ spec éªŒè¯"""
    print("ğŸ§ª æµ‹è¯•åŠ¨æ€ Spec Runner\n")

    # æ–¹å¼ 1: ä½¿ç”¨ YAML ruleset æ ¼å¼ (å†…å­˜ä¸­å®šä¹‰)
    ruleset = {
        "name": "Figma vs Expected Styles",
        "rules": [
            {
                "name": "style_keys_coverage",
                "source": {
                    "module": "file.read",
                    "params": {
                        "path": "./examples/happy-test/figma-styles.json"
                    }
                },
                "target": {
                    "module": "file.read",
                    "params": {
                        "path": "./examples/happy-test/expected-styles.json"
                    }
                },
                "compare": "bidirectional",
                "pass_criteria": "80%"  # 80% è¦†ç›–ç‡å³é€šè¿‡
            }
        ]
    }

    print("ğŸ“‹ Ruleset:")
    print(f"   åç§°: {ruleset['name']}")
    print(f"   è§„åˆ™æ•°: {len(ruleset['rules'])}")
    print()

    # æ‰§è¡ŒéªŒè¯
    result = await run_spec_ruleset(ruleset)

    # æ˜¾ç¤ºç»“æœ
    print("ğŸ“Š éªŒè¯ç»“æœ:")
    print(f"   æ€»è§„åˆ™æ•°: {result['summary']['total_rules']}")
    print(f"   é€šè¿‡: {result['summary']['passed']}")
    print(f"   å¤±è´¥: {result['summary']['failed']}")
    print(f"   é€šè¿‡ç‡: {result['summary']['pass_rate']}%")
    print()

    for r in result['results']:
        status = "âœ…" if r['passed'] else "âŒ"
        print(f"   {status} {r['name']}")
        print(f"      Source keys: {r['source_count']}")
        print(f"      Target keys: {r['target_count']}")
        print(f"      Matched: {r['matched_count']}")
        print(f"      Coverage: {r['coverage']}%")
        if r['missing_count'] > 0:
            print(f"      Missing in target: {r['missing_in_target'][:5]}...")
        if r['orphaned_count'] > 0:
            print(f"      Orphaned in target: {r['orphaned_in_target'][:5]}...")
        print()


async def test_module_execution():
    """æµ‹è¯•å•ç‹¬æ¨¡ç»„æ‰§è¡Œ"""
    print("ğŸ”§ æµ‹è¯•å•ç‹¬æ¨¡ç»„æ‰§è¡Œ\n")

    # è¯»å– Figma æ ·å¼
    result = await execute_module_dynamic("file.read", {
        "path": "./examples/happy-test/figma-styles.json"
    })

    if result.get('ok'):
        keys = extract_keys(result)
        print(f"   Figma styles keys: {sorted(keys)}")
    else:
        print(f"   âŒ Error: {result.get('error')}")

    # è¯»å–æœŸæœ›æ ·å¼
    result = await execute_module_dynamic("file.read", {
        "path": "./examples/happy-test/expected-styles.json"
    })

    if result.get('ok'):
        keys = extract_keys(result)
        print(f"   Expected styles keys: {sorted(keys)}")
    else:
        print(f"   âŒ Error: {result.get('error')}")


if __name__ == "__main__":
    print("=" * 60)
    asyncio.run(test_module_execution())
    print()
    print("=" * 60)
    asyncio.run(test_dynamic_spec())
